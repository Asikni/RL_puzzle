{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#USING Q-LEARNING TO SOLVE MAZE PROBLEM:\n",
        "\n"
      ],
      "metadata": {
        "id": "VyfkHZc2O2sp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**So we have a maze of 25*25 dimension, & we want our agent to reach the end point. In doing so it has to avoid the bombs/ghosts, which are moving up & down or right & left. If it comes in contact with any bomb the game is over and agent starts from the beginning. Also there are walls in between, which our agent can't pass. So our agent has to find the fastest route to the finish point.**"
      ],
      "metadata": {
        "id": "M2A6Gt1ZECMN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_p1riQlN2r2A"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import operator\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import random\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWpP9GwJ2vhJ"
      },
      "outputs": [],
      "source": [
        "class GridWorld:\n",
        "    ## Initialise starting data\n",
        "    def __init__(self):\n",
        "        # Set information about the gridworld\n",
        "        self.height = 25                         #it is a 25*25 grid world\n",
        "        self.width = 25\n",
        "        self.grid = np.zeros(( self.height, self.width)) - 1    #assigning the rewards for each step i.e. -1 for each step\n",
        "\n",
        "        #walls\n",
        "        self.grid[2:21, 5] = -math.inf\n",
        "        self.grid[2:21,0] = -math.inf\n",
        "        self.grid[2:21,2] = -math.inf\n",
        "        self.grid[2:21,8] = -math.inf\n",
        "        self.grid[5,11:24] = -math.inf\n",
        "        self.grid[8,11:24] = -math.inf\n",
        "        self.grid[11, 11:24] = -math.inf\n",
        "        self.grid[14,11:24] = -math.inf\n",
        "        self.grid[17,11:24] = -math.inf\n",
        "        self.grid[20,11:24] = -math.inf\n",
        "        self.grid[2,11:24] = -math.inf\n",
        "        self.grid[22,0:23] = -math.inf\n",
        "\n",
        "\n",
        "        self.current_location = (0,0)    #Our robot will start at (0,0) location\n",
        "        self.End_location = (24,0)       #where robot has to reach\n",
        "\n",
        "        #bombs/ghosts in our way\n",
        "        self.ghost_location = (18,4)\n",
        "        self.ghost_location_2 = (6,6)\n",
        "        self.ghost_location_3 = (15,7)\n",
        "        self.ghost_location_4 = (2,10)\n",
        "        self.ghost_location_5 = (11,24)\n",
        "        self.ghost_location_6 = (21,8)\n",
        "        self.ghost_location_7 = (1,18)\n",
        "        self.terminal_states = [self.End_location,self.ghost_location,self.ghost_location_2,self.ghost_location_3,self.ghost_location_4,\n",
        "                                self.ghost_location_5,self.ghost_location_6,self.ghost_location_7]   #where our game ends\n",
        "\n",
        "        # Set grid rewards for special cells\n",
        "        self.grid[ self.ghost_location[0], self.ghost_location[1]] = -100\n",
        "        self.grid[ self.ghost_location_2[0], self.ghost_location_2[1]] = -100\n",
        "        self.grid[ self.ghost_location_3[0], self.ghost_location_3[1]] = -100\n",
        "        self.grid[ self.ghost_location_4[0], self.ghost_location_4[1]] = -100\n",
        "        self.grid[ self.ghost_location_5[0], self.ghost_location_5[1]] = -100\n",
        "        self.grid[ self.ghost_location_6[0], self.ghost_location_6[1]] = -100\n",
        "        self.grid[ self.ghost_location_7[0], self.ghost_location_7[1]] = -100\n",
        "        self.grid[ self.End_location[0], self.End_location[1]] = 100\n",
        "        self.grid[ self.current_location[0], self.current_location[1]] = -1\n",
        "\n",
        "        # Set available actions\n",
        "        self.actions = ['NORTH', 'SOUTH', 'WEST', 'EAST']\n",
        "\n",
        "\n",
        "    ## Put methods here:\n",
        "    def get_available_actions(self):\n",
        "        \"\"\"Returns possible actions\"\"\"\n",
        "        return self.actions\n",
        "\n",
        "    def get_reward(self, new_location):\n",
        "        \"\"\"Returns the reward for an input position\"\"\"\n",
        "        return self.grid[ new_location[0], new_location[1]]\n",
        "\n",
        "    def make_step(self, action):\n",
        "        \"\"\"Moves the agent in the specified direction. If agent is at a border, agent stays still\n",
        "        but takes negative reward. Function returns the reward for the move.\"\"\"\n",
        "        # Store previous location\n",
        "        last_location = self.current_location\n",
        "\n",
        "        if action == 'NORTH':\n",
        "            # If agent is at the top, stay still, collect reward\n",
        "            if last_location[0] == 0 :\n",
        "                reward = self.get_reward(last_location)\n",
        "            else:\n",
        "                self.current_location = ( self.current_location[0] - 1, self.current_location[1])       #updating the current location\n",
        "                if  self.grid[ self.current_location[0], self.current_location[1]] != -math.inf:\n",
        "                  reward = self.get_reward(self.current_location)                                         #taking reward of the current location\n",
        "                else:\n",
        "                  self.current_location = last_location\n",
        "                  reward = self.get_reward(last_location)\n",
        "        # DOWN\n",
        "        elif action == 'SOUTH':\n",
        "            # If agent is at bottom, stay still, collect reward\n",
        "            if last_location[0] == self.height - 1:\n",
        "                reward = self.get_reward(last_location)\n",
        "            else:\n",
        "                self.current_location = ( self.current_location[0] + 1, self.current_location[1])\n",
        "                if  self.grid[ self.current_location[0], self.current_location[1]] != -math.inf:\n",
        "                  reward = self.get_reward(self.current_location)\n",
        "                else:\n",
        "                  self.current_location = last_location\n",
        "                  reward = self.get_reward(last_location)\n",
        "        # LEFT\n",
        "        elif action == 'WEST':\n",
        "            # If agent is at the left, stay still, collect reward\n",
        "            if last_location[1] == 0:\n",
        "                reward = self.get_reward(last_location)\n",
        "            else:\n",
        "                self.current_location = ( self.current_location[0], self.current_location[1] - 1)\n",
        "                if  self.grid[ self.current_location[0], self.current_location[1]] != -math.inf:\n",
        "                  reward = self.get_reward(self.current_location)\n",
        "                else:\n",
        "                  self.current_location = last_location\n",
        "                  reward = self.get_reward(last_location)\n",
        "        # RIGHT\n",
        "        elif action == 'EAST':\n",
        "            # If agent is at the right, stay still, collect reward\n",
        "            if last_location[1] == self.width - 1:\n",
        "                reward = self.get_reward(last_location)\n",
        "            else:\n",
        "                self.current_location = ( self.current_location[0], self.current_location[1] + 1)\n",
        "                if  self.grid[ self.current_location[0], self.current_location[1]] != -math.inf:\n",
        "                  reward = self.get_reward(self.current_location)\n",
        "                else:\n",
        "                  self.current_location = last_location\n",
        "                  reward = self.get_reward(last_location)\n",
        "        return reward\n",
        "\n",
        "    def check_state(self):\n",
        "\n",
        "        \"\"\"Check if the agent is in a terminal state, if so return 'END GAME'\"\"\"\n",
        "        if self.current_location in self.terminal_states:\n",
        "          if self.current_location == self.terminal_states[0]:\n",
        "            return 'Agent has reached the goal'\n",
        "          else:\n",
        "            return 'Caught by bomb'\n",
        "\n",
        "    def show(self):       #shows the environment\n",
        "        for i in range(0, self.height):\n",
        "            print('---------------------------------------------------------------------------------------------------------------------------')\n",
        "            out = '|'\n",
        "            for j in range(0, self.width):\n",
        "                if self.grid[i, j] == -100:\n",
        "                    token = ' ‚ò†Ô∏è'                    #bombs/ghosts\n",
        "                elif self.grid[i, j] == -math.inf:\n",
        "                    token = '‚ñá'                     #walls\n",
        "                elif self.grid[i, j] == 100:\n",
        "                    token = 'üçï'                     #final destination\n",
        "                elif self.grid[i,j] == -1:\n",
        "\n",
        "                    token = '‚ôõ'                     #our agent\n",
        "\n",
        "                else:\n",
        "                  token = '_ '                       #rest of grid\n",
        "\n",
        "                out += token + ' | '\n",
        "            print(out)\n",
        "        print('-------------------------------------------------------------------------------------------------------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZGWVBgi4u6X",
        "outputId": "2483c005-1df5-4722-96c9-8be8cbc624e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------------------------------------------------\n",
            "|‚ôõ | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | \n",
            "---------------------------------------------------------------------------------------------------------------------------\n",
            "|_  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  |  ‚ò†Ô∏è | _  | _  | _  | _  | _  | _  | \n",
            "---------------------------------------------------------------------------------------------------------------------------\n",
            "|‚ñá | _  | ‚ñá | _  | _  | ‚ñá | _  | _  | ‚ñá | _  |  ‚ò†Ô∏è | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | _  | \n",
            "---------------------------------------------------------------------------------------------------------------------------\n",
            "|‚ñá | _  | ‚ñá | _  | _  | ‚ñá | _  | _  | ‚ñá | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | \n",
            "---------------------------------------------------------------------------------------------------------------------------\n",
            "|‚ñá | _  | ‚ñá | _  | _  | ‚ñá | _  | _  | ‚ñá | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | \n",
            "---------------------------------------------------------------------------------------------------------------------------\n",
            "|‚ñá | _  | ‚ñá | _  | _  | ‚ñá | _  | _  | ‚ñá | _  | _  | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | _  | \n",
            "---------------------------------------------------------------------------------------------------------------------------\n",
            "|‚ñá | _  | ‚ñá | _  | _  | ‚ñá |  ‚ò†Ô∏è | _  | ‚ñá | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | \n",
            "---------------------------------------------------------------------------------------------------------------------------\n",
            "|‚ñá | _  | ‚ñá | _  | _  | ‚ñá | _  | _  | ‚ñá | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | \n",
            "---------------------------------------------------------------------------------------------------------------------------\n",
            "|‚ñá | _  | ‚ñá | _  | _  | ‚ñá | _  | _  | ‚ñá | _  | _  | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | _  | \n",
            "---------------------------------------------------------------------------------------------------------------------------\n",
            "|‚ñá | _  | ‚ñá | _  | _  | ‚ñá | _  | _  | ‚ñá | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | \n",
            "---------------------------------------------------------------------------------------------------------------------------\n",
            "|‚ñá | _  | ‚ñá | _  | _  | ‚ñá | _  | _  | ‚ñá | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | \n",
            "---------------------------------------------------------------------------------------------------------------------------\n",
            "|‚ñá | _  | ‚ñá | _  | _  | ‚ñá | _  | _  | ‚ñá | _  | _  | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá |  ‚ò†Ô∏è | \n",
            "---------------------------------------------------------------------------------------------------------------------------\n",
            "|‚ñá | _  | ‚ñá | _  | _  | ‚ñá | _  | _  | ‚ñá | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | \n",
            "---------------------------------------------------------------------------------------------------------------------------\n",
            "|‚ñá | _  | ‚ñá | _  | _  | ‚ñá | _  | _  | ‚ñá | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | \n",
            "---------------------------------------------------------------------------------------------------------------------------\n",
            "|‚ñá | _  | ‚ñá | _  | _  | ‚ñá | _  | _  | ‚ñá | _  | _  | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | _  | \n",
            "---------------------------------------------------------------------------------------------------------------------------\n",
            "|‚ñá | _  | ‚ñá | _  | _  | ‚ñá | _  |  ‚ò†Ô∏è | ‚ñá | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | \n",
            "---------------------------------------------------------------------------------------------------------------------------\n",
            "|‚ñá | _  | ‚ñá | _  | _  | ‚ñá | _  | _  | ‚ñá | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | \n",
            "---------------------------------------------------------------------------------------------------------------------------\n",
            "|‚ñá | _  | ‚ñá | _  | _  | ‚ñá | _  | _  | ‚ñá | _  | _  | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | _  | \n",
            "---------------------------------------------------------------------------------------------------------------------------\n",
            "|‚ñá | _  | ‚ñá | _  |  ‚ò†Ô∏è | ‚ñá | _  | _  | ‚ñá | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | \n",
            "---------------------------------------------------------------------------------------------------------------------------\n",
            "|‚ñá | _  | ‚ñá | _  | _  | ‚ñá | _  | _  | ‚ñá | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | \n",
            "---------------------------------------------------------------------------------------------------------------------------\n",
            "|‚ñá | _  | ‚ñá | _  | _  | ‚ñá | _  | _  | ‚ñá | _  | _  | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | _  | \n",
            "---------------------------------------------------------------------------------------------------------------------------\n",
            "|_  | _  | _  | _  | _  | _  | _  | _  |  ‚ò†Ô∏è | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | \n",
            "---------------------------------------------------------------------------------------------------------------------------\n",
            "|‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | ‚ñá | _  | _  | \n",
            "---------------------------------------------------------------------------------------------------------------------------\n",
            "|_  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | \n",
            "---------------------------------------------------------------------------------------------------------------------------\n",
            "|üçï | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | _  | \n",
            "-------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "gw= GridWorld()\n",
        "gw.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q-learning initialization:"
      ],
      "metadata": {
        "id": "-6MzfW7zF7j0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Our agent can perform four actions.. North(Up), South(down), East(right), West(left) & can move only one step at a time.**\n",
        "**We are using q-learning to solve our grid problem.**"
      ],
      "metadata": {
        "id": "m8LLfkISGSQq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_oNnI7H5AxQh"
      },
      "outputs": [],
      "source": [
        "class Q_Agent():\n",
        "    # Intialise\n",
        "    def __init__(self, environment, epsilon=.3, alpha=0.3, gamma=.9):\n",
        "        self.environment = environment\n",
        "        self.q_table = dict() # Store all Q-values in dictionary of dictionaries\n",
        "        for x in range(environment.height): # Loop through all possible grid spaces, create sub-dictionary for each\n",
        "            for y in range(environment.width):\n",
        "                self.q_table[(x,y)] = {'NORTH':0, 'SOUTH':0, 'EAST':0, 'WEST':0,} # Populate sub-dictionary with zero values for possible moves\n",
        "                #4 different actions are possible in each state\n",
        "                #initializing q table with values = 0.\n",
        "        self.epsilon = epsilon\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def choose_action(self, available_actions):\n",
        "        \"\"\"Returns the optimal action from Q-Value table. If multiple optimal actions, chooses random choice.\n",
        "        Will make an exploratory random action dependent on epsilon.\"\"\"\n",
        "        if np.random.uniform(0,1) < self.epsilon:                            #if the value is less than epsilon we take random action  (exploration)\n",
        "            action = available_actions[np.random.randint(0, len(available_actions))]\n",
        "        else:                                                                #else max value of action\n",
        "            q_values_of_state = self.q_table[self.environment.current_location]    #current location updated earlier\n",
        "            maxValue = max(q_values_of_state.values())   #take the max value & followed by its corresponding action.\n",
        "            action = np.random.choice([k for k, v in q_values_of_state.items() if v == maxValue])   #if multiple optimal actions...then take a random one\n",
        "            #action corresponding to maxvalue\n",
        "        return action\n",
        "\n",
        "    def learn(self, old_state, reward, new_state, action,ghost_location,ghost_location_2,ghost_location_3,ghost_location_4,ghost_location_5,ghost_location_6,ghost_location_7):\n",
        "        \"\"\"Updates the Q-value table using Q-learning\"\"\"\n",
        "        q_values_of_state = self.q_table[new_state]      #dict of actions of new state & respective q values\n",
        "        self.ghost_location = ghost_location\n",
        "        self.ghost_location_2 = ghost_location_2\n",
        "        self.ghost_location_3 = ghost_location_3\n",
        "        self.ghost_location_4 = ghost_location_4\n",
        "        self.ghost_location_5 = ghost_location_5\n",
        "        self.ghost_location_6 = ghost_location_6\n",
        "        self.ghost_location_7 = ghost_location_7\n",
        "        max_q_value_in_new_state = max(q_values_of_state.values())\n",
        "        current_q_value = self.q_table[old_state][action]\n",
        "\n",
        "        self.q_table[old_state][action] = (1 - self.alpha) * current_q_value + self.alpha * (reward + self.gamma * max_q_value_in_new_state)  #q-learning equation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ghosts 1,2,3,4, & 5 move vertically while as ghosts 6,7 move horizontally.**"
      ],
      "metadata": {
        "id": "XeDnPKiS_Wdo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VdJfxKe7BVx0"
      },
      "outputs": [],
      "source": [
        "def play(environment, agent, trials=100, max_steps_per_episode=2500, learn=False):    #max number of steps in which agent has to reach to the destination\n",
        "\n",
        "    \"\"\"The play function runs iterations and updates Q-values if desired.\"\"\"\n",
        "    reward_per_episode = [] # Initialise performance log\n",
        "    new_states =[]\n",
        "    e_s = []\n",
        "    g_s = []\n",
        "\n",
        "    ghost_location = environment.ghost_location\n",
        "    ghost_location_2 = environment.ghost_location_2\n",
        "    ghost_location_3 = environment.ghost_location_3\n",
        "    ghost_location_4 = environment.ghost_location_4\n",
        "    ghost_location_5 = environment.ghost_location_5\n",
        "    ghost_location_6 = environment.ghost_location_6\n",
        "    ghost_location_7 = environment.ghost_location_7\n",
        "    for trial in range(trials): # Run trials\n",
        "      #when the ghosts change their positions after some iterations\n",
        "      if (trial % 7) == 2:                                        #for ghost location 1 & 2\n",
        "        if np.random.uniform(0,1) >= .5 :\n",
        "          environment.ghost_location = ghost_location\n",
        "          environment.ghost_location_2 = ghost_location_2\n",
        "\n",
        "          if environment.ghost_location[0] == 0:\n",
        "            environment.ghost_location =  environment.ghost_location[0]+1 ,environment.ghost_location[1]\n",
        "            environment.grid[ environment.ghost_location[0]+1 , environment.ghost_location[1]] = -100\n",
        "          else:\n",
        "            environment.grid[ environment.ghost_location[0], environment.ghost_location[1]] = -1\n",
        "            environment.grid[ environment.ghost_location[0] - 1, environment.ghost_location[1]] = -100\n",
        "            environment.ghost_location = (environment.ghost_location[0] -1,environment.ghost_location[1])\n",
        "\n",
        "          if environment.ghost_location_2[0] == 0:\n",
        "            environment.ghost_location_2 =  environment.ghost_location_2[0],environment.ghost_location_2[1]\n",
        "            environment.grid[ environment.ghost_location_2[0], environment.ghost_location_2[1]] = -100\n",
        "          else:\n",
        "            environment.grid[ environment.ghost_location_2[0], environment.ghost_location_2[1]] = -1\n",
        "            environment.grid[ environment.ghost_location_2[0] - 1, environment.ghost_location_2[1]] = -100\n",
        "            environment.ghost_location_2 = (environment.ghost_location_2[0] - 1, environment.ghost_location_2[1])\n",
        "\n",
        "\n",
        "\n",
        "        else:\n",
        "          environment.ghost_location = ghost_location\n",
        "          environment.ghost_location_2 = ghost_location_2\n",
        "\n",
        "          if environment.ghost_location[0] == 21:\n",
        "            environment.ghost_location =  environment.ghost_location[0] -1 ,environment.ghost_location[1]\n",
        "            environment.grid[ environment.ghost_location[0] - 1 , environment.ghost_location[1]] = -100\n",
        "          else:\n",
        "            environment.grid[ environment.ghost_location[0], environment.ghost_location[1]] = -1\n",
        "            environment.grid[ environment.ghost_location[0] + 1, environment.ghost_location[1]] = -100\n",
        "            environment.ghost_location = (environment.ghost_location[0] + 1,environment.ghost_location[1])\n",
        "\n",
        "          if environment.ghost_location_2[0] == 21:\n",
        "            environment.ghost_location_2 =  environment.ghost_location_2[0]  ,environment.ghost_location_2[1]\n",
        "            environment.grid[ environment.ghost_location_2[0]  , environment.ghost_location_2[1]] = -100\n",
        "          else:\n",
        "            environment.grid[ environment.ghost_location_2[0], environment.ghost_location_2[1]] = -1\n",
        "            environment.grid[ environment.ghost_location_2[0] + 1, environment.ghost_location_2[1]] = -100\n",
        "            environment.ghost_location_2 = (environment.ghost_location_2[0] + 1, environment.ghost_location_2[1])\n",
        "\n",
        "        cumulative_reward = 0 # Initialise values of each game\n",
        "\n",
        "        step = 0\n",
        "        game_over = False\n",
        "        new_states = []\n",
        "\n",
        "        while step < max_steps_per_episode and game_over != True: # Run until max steps or until game is finished\n",
        "          ghost_location = environment.ghost_location\n",
        "          ghost_location_2 = environment.ghost_location_2\n",
        "\n",
        "          old_state = environment.current_location             #defining old state\n",
        "          action = agent.choose_action(environment.actions)     #depending on whether we place agent as random agent or q agent\n",
        "          reward = environment.make_step(action)             #reward plus updation of current_location\n",
        "          new_state = environment.current_location\n",
        "          new_states.append(new_state)\n",
        "          if learn == True: # Update Q-values if learning is specified\n",
        "              agent.learn(old_state, reward, new_state, action,ghost_location,ghost_location_2,ghost_location_3,ghost_location_4,ghost_location_5,\n",
        "                          ghost_location_6,ghost_location_7)\n",
        "\n",
        "          cumulative_reward += reward    #total reward collected\n",
        "          step += 1\n",
        "\n",
        "\n",
        "          if environment.check_state() == 'Agent has reached the goal': # If game is in terminal state, game over and start next trial\n",
        "              rand = np.random.uniform(0,1000)\n",
        "              e_s.append(rand)\n",
        "              environment.__init__()\n",
        "              game_over = True\n",
        "          elif environment.check_state() == 'Caught by bomb':\n",
        "              rand = np.random.uniform(0,1000)\n",
        "              g_s.append(rand)\n",
        "              environment.__init__()\n",
        "              game_over = True\n",
        "\n",
        "        reward_per_episode.append(cumulative_reward) # Append reward for current trial to performance log, list of rewards for each iteration\n",
        "\n",
        "\n",
        "      elif (trial % 10) == 1:                             #for ghost location 3 & 4\n",
        "        if np.random.uniform(0,1) >= .4 :\n",
        "\n",
        "          environment.ghost_location_3  = ghost_location_3\n",
        "          environment.ghost_location_4  = ghost_location_4\n",
        "\n",
        "\n",
        "          if environment.ghost_location_3[0] == 0:\n",
        "            environment.ghost_location_3 =  environment.ghost_location_3[0] +1,environment.ghost_location_3[1]\n",
        "            environment.grid[ environment.ghost_location_3[0] +1 , environment.ghost_location_3[1]] = -100\n",
        "          else:\n",
        "            environment.grid[ environment.ghost_location_3[0], environment.ghost_location_3[1]] = -1\n",
        "            environment.grid[ environment.ghost_location_3[0] - 1, environment.ghost_location_3[1]] = -100\n",
        "            environment.ghost_location_3 = (environment.ghost_location_3[0] -1,environment.ghost_location_3[1])\n",
        "\n",
        "          if environment.ghost_location_4[0] == 0:\n",
        "            environment.ghost_location_4 =  environment.ghost_location_4[0] ,environment.ghost_location_4[1]\n",
        "            environment.grid[ environment.ghost_location_4[0] , environment.ghost_location_4[1]] = -100\n",
        "          else:\n",
        "            environment.grid[ environment.ghost_location_4[0], environment.ghost_location_4[1]] = -1\n",
        "            environment.grid[ environment.ghost_location_4[0] - 1, environment.ghost_location_4[1]] = -100\n",
        "            environment.ghost_location_4 = (environment.ghost_location_4[0] - 1, environment.ghost_location_4[1])\n",
        "\n",
        "\n",
        "\n",
        "        else:\n",
        "\n",
        "          environment.ghost_location_3  = ghost_location_3\n",
        "          environment.ghost_location_4  = ghost_location_4\n",
        "\n",
        "\n",
        "          if environment.ghost_location_3[0] == 21:\n",
        "            environment.ghost_location_3 =  environment.ghost_location_3[0] -1,environment.ghost_location_3[1]\n",
        "            environment.grid[ environment.ghost_location_3[0]-1 , environment.ghost_location_3[1]] = -100\n",
        "          else:\n",
        "            environment.grid[ environment.ghost_location_3[0], environment.ghost_location_3[1]] = -1\n",
        "            environment.grid[ environment.ghost_location_3[0] + 1, environment.ghost_location_3[1]] = -100\n",
        "            environment.ghost_location_3 = (environment.ghost_location_3[0] + 1,environment.ghost_location_3[1])\n",
        "\n",
        "          if environment.ghost_location_4[0] == 21:\n",
        "            environment.ghost_location_4 =  environment.ghost_location_4[0] ,environment.ghost_location_4[1]\n",
        "            environment.grid[ environment.ghost_location_4[0] , environment.ghost_location_4[1]] = -100\n",
        "          else:\n",
        "            environment.grid[ environment.ghost_location_4[0], environment.ghost_location_4[1]] = -1\n",
        "            environment.grid[ environment.ghost_location_4[0] + 1, environment.ghost_location_4[1]] = -100\n",
        "            environment.ghost_location_4 = (environment.ghost_location_4[0] + 1, environment.ghost_location_4[1])\n",
        "\n",
        "        cumulative_reward = 0 # Initialise values of each game\n",
        "\n",
        "        step = 0\n",
        "        game_over = False\n",
        "        new_states = []\n",
        "\n",
        "        while step < max_steps_per_episode and game_over != True: # Run until max steps or until game is finished\n",
        "          ghost_location_3 = environment.ghost_location_3\n",
        "          ghost_location_4 = environment.ghost_location_4\n",
        "\n",
        "          old_state = environment.current_location             #defining old state\n",
        "          action = agent.choose_action(environment.actions)     #depending on whether we place agent as random agent or q agent\n",
        "          reward = environment.make_step(action)             #reward plus updation of current_location\n",
        "          new_state = environment.current_location\n",
        "          new_states.append(new_state)\n",
        "          if learn == True: # Update Q-values if learning is specified\n",
        "              agent.learn(old_state, reward, new_state, action,ghost_location,ghost_location_2,ghost_location_3,ghost_location_4,ghost_location_5,\n",
        "                          ghost_location_6,ghost_location_7)\n",
        "\n",
        "          cumulative_reward += reward    #total reward collected\n",
        "          step += 1\n",
        "\n",
        "\n",
        "          if environment.check_state() == 'Agent has reached the goal': # If game is in terminal state, game over and start next trial\n",
        "              rand = np.random.uniform(0,1000)\n",
        "              e_s.append(rand)\n",
        "              environment.__init__()\n",
        "              game_over = True\n",
        "          elif environment.check_state() == 'Caught by bomb':\n",
        "              rand = np.random.uniform(0,1000)\n",
        "              g_s.append(rand)\n",
        "              environment.__init__()\n",
        "              game_over = True\n",
        "\n",
        "        reward_per_episode.append(cumulative_reward) # Append reward for current trial to performance log, list of rewards for each iteration\n",
        "\n",
        "      elif (trial % 6) == 1:                             #for ghost location 5\n",
        "        if np.random.uniform(0,1) >= .6 :\n",
        "          environment.ghost_location_5  = ghost_location_5\n",
        "\n",
        "          if environment.ghost_location_5[0] == 0:\n",
        "            environment.ghost_location_5 =  environment.ghost_location_5[0] ,environment.ghost_location_5[1]\n",
        "            environment.grid[ environment.ghost_location_5[0] , environment.ghost_location_5[1]] = -100\n",
        "          else:\n",
        "            environment.grid[ environment.ghost_location_5[0], environment.ghost_location_5[1]] = -1\n",
        "            environment.grid[ environment.ghost_location_5[0] - 1, environment.ghost_location_5[1]] = -100\n",
        "            environment.ghost_location_5 = (environment.ghost_location_5[0] -1,environment.ghost_location_5[1])\n",
        "\n",
        "        else:\n",
        "\n",
        "          environment.ghost_location_5  = ghost_location_5\n",
        "\n",
        "          if environment.ghost_location_5[0] == 24:\n",
        "            environment.ghost_location_5 =  environment.ghost_location_5[0] ,environment.ghost_location_5[1]\n",
        "            environment.grid[ environment.ghost_location_5[0] , environment.ghost_location_5[1]] = -100\n",
        "          else:\n",
        "            environment.grid[ environment.ghost_location_5[0], environment.ghost_location_5[1]] = -1\n",
        "            environment.grid[ environment.ghost_location_5[0] + 1, environment.ghost_location_5[1]] = -100\n",
        "            environment.ghost_location_5 = (environment.ghost_location_5[0] + 1,environment.ghost_location_5[1])\n",
        "\n",
        "        cumulative_reward = 0 # Initialise values of each game\n",
        "\n",
        "        step = 0\n",
        "        game_over = False\n",
        "        new_states = []\n",
        "\n",
        "        while step < max_steps_per_episode and game_over != True: # Run until max steps or until game is finished\n",
        "          ghost_location_5 = environment.ghost_location_5\n",
        "\n",
        "\n",
        "          old_state = environment.current_location             #defining old state\n",
        "          action = agent.choose_action(environment.actions)     #depending on whether we place agent as random agent or q agent\n",
        "          reward = environment.make_step(action)             #reward plus updation of current_location\n",
        "          new_state = environment.current_location\n",
        "          new_states.append(new_state)\n",
        "          if learn == True: # Update Q-values if learning is specified\n",
        "              agent.learn(old_state, reward, new_state, action,ghost_location,ghost_location_2,ghost_location_3,ghost_location_4,ghost_location_5,\n",
        "                          ghost_location_6,ghost_location_7)\n",
        "\n",
        "          cumulative_reward += reward    #total reward collected\n",
        "          step += 1\n",
        "\n",
        "\n",
        "          if environment.check_state() == 'Agent has reached the goal': # If game is in terminal state, game over and start next trial\n",
        "              rand = np.random.uniform(0,1000)\n",
        "              e_s.append(rand)\n",
        "              environment.__init__()\n",
        "              game_over = True\n",
        "          elif environment.check_state() == 'Caught by bomb':\n",
        "              rand = np.random.uniform(0,1000)\n",
        "              g_s.append(rand)\n",
        "              environment.__init__()\n",
        "              game_over = True\n",
        "\n",
        "        reward_per_episode.append(cumulative_reward) # Append reward for current trial to performance log, list of rewards for each iteration\n",
        "\n",
        "      elif (trial % 9) == 1:                             #for ghost location 6\n",
        "        if np.random.uniform(0,1) >= .6 :\n",
        "\n",
        "          environment.ghost_location_6  = ghost_location_6\n",
        "\n",
        "\n",
        "          if environment.ghost_location_6[1] == 24:\n",
        "            environment.ghost_location_6 =  environment.ghost_location_6[0] ,environment.ghost_location_6[1]\n",
        "            environment.grid[ environment.ghost_location_6[0] , environment.ghost_location_6[1]] = -100\n",
        "          else:\n",
        "            environment.grid[ environment.ghost_location_6[0], environment.ghost_location_6[1]] = -1\n",
        "            environment.grid[ environment.ghost_location_6[0] , environment.ghost_location_6[1] + 1] = -100\n",
        "            environment.ghost_location_6 = (environment.ghost_location_6[0],environment.ghost_location_6[1]+1)\n",
        "\n",
        "        else:\n",
        "\n",
        "          environment.ghost_location_6  = ghost_location_6\n",
        "\n",
        "          if environment.ghost_location_6[1] == 0:\n",
        "            environment.ghost_location_6 =  environment.ghost_location_6[0] ,environment.ghost_location_6[1]\n",
        "            environment.grid[ environment.ghost_location_6[0] , environment.ghost_location_6[1]] = -100\n",
        "          else:\n",
        "            environment.grid[ environment.ghost_location_6[0], environment.ghost_location_6[1]] = -1\n",
        "            environment.grid[ environment.ghost_location_6[0] , environment.ghost_location_6[1] - 1] = -100\n",
        "            environment.ghost_location_6 = (environment.ghost_location_6[0],environment.ghost_location_6[1] - 1)\n",
        "\n",
        "        cumulative_reward = 0 # Initialise values of each game\n",
        "\n",
        "        step = 0\n",
        "        game_over = False\n",
        "        new_states = []\n",
        "\n",
        "        while step < max_steps_per_episode and game_over != True: # Run until max steps or until game is finished\n",
        "          ghost_location_6 = environment.ghost_location_6\n",
        "\n",
        "\n",
        "          old_state = environment.current_location             #defining old state\n",
        "          action = agent.choose_action(environment.actions)     #depending on whether we place agent as random agent or q agent\n",
        "          reward = environment.make_step(action)             #reward plus updation of current_location\n",
        "          new_state = environment.current_location\n",
        "          new_states.append(new_state)\n",
        "          if learn == True: # Update Q-values if learning is specified\n",
        "              agent.learn(old_state, reward, new_state, action,ghost_location,ghost_location_2,ghost_location_3,ghost_location_4,ghost_location_5,\n",
        "                          ghost_location_6,ghost_location_7)\n",
        "\n",
        "          cumulative_reward += reward    #total reward collected\n",
        "          step += 1\n",
        "\n",
        "\n",
        "          if environment.check_state() == 'Agent has reached the goal': # If game is in terminal state, game over and start next trial\n",
        "              rand = np.random.uniform(0,1000)\n",
        "              e_s.append(rand)\n",
        "              environment.__init__()\n",
        "              game_over = True\n",
        "          elif environment.check_state() == 'Caught by bomb':\n",
        "              rand = np.random.uniform(0,1000)\n",
        "              g_s.append(rand)\n",
        "              environment.__init__()\n",
        "              game_over = True\n",
        "\n",
        "        reward_per_episode.append(cumulative_reward) # Append reward for current trial to performance log, list of rewards for each iteration\n",
        "\n",
        "      elif (trial % 4) == 1:                             #for ghost location 7\n",
        "        if np.random.uniform(0,1) >= .4 :\n",
        "\n",
        "          environment.ghost_location_7  = ghost_location_7\n",
        "\n",
        "          if environment.ghost_location_7[1] == 24:\n",
        "            environment.ghost_location_7 =  environment.ghost_location_7[0] ,environment.ghost_location_7[1]\n",
        "            environment.grid[ environment.ghost_location_7[0] , environment.ghost_location_7[1]] = -100\n",
        "          else:\n",
        "            environment.grid[ environment.ghost_location_7[0], environment.ghost_location_7[1]] = -1\n",
        "            environment.grid[ environment.ghost_location_7[0] , environment.ghost_location_7[1] + 1] = -100\n",
        "            environment.ghost_location_7 = (environment.ghost_location_7[0],environment.ghost_location_7[1]+1)\n",
        "\n",
        "        else:\n",
        "\n",
        "          environment.ghost_location_7  = ghost_location_7\n",
        "\n",
        "          if environment.ghost_location_7[1] == 11 :\n",
        "            environment.ghost_location_7 =  environment.ghost_location_7[0] ,environment.ghost_location_7[1]\n",
        "            environment.grid[ environment.ghost_location_7[0] , environment.ghost_location_7[1]] = -100\n",
        "          else:\n",
        "            environment.grid[ environment.ghost_location_7[0], environment.ghost_location_7[1]] = -1\n",
        "            environment.grid[ environment.ghost_location_7[0] , environment.ghost_location_7[1] - 1] = -100\n",
        "            environment.ghost_location_7 = (environment.ghost_location_7[0],environment.ghost_location_7[1] - 1)\n",
        "\n",
        "        cumulative_reward = 0 # Initialise values of each game\n",
        "\n",
        "        step = 0\n",
        "        game_over = False\n",
        "        new_states = []\n",
        "\n",
        "        while step < max_steps_per_episode and game_over != True: # Run until max steps or until game is finished\n",
        "          ghost_location_7 = environment.ghost_location_7\n",
        "\n",
        "\n",
        "          old_state = environment.current_location             #defining old state\n",
        "          action = agent.choose_action(environment.actions)     #depending on whether we place agent as random agent or q agent\n",
        "          reward = environment.make_step(action)             #reward plus updation of current_location\n",
        "          new_state = environment.current_location\n",
        "          new_states.append(new_state)\n",
        "          if learn == True: # Update Q-values if learning is specified\n",
        "              agent.learn(old_state, reward, new_state, action,ghost_location,ghost_location_2,ghost_location_3,ghost_location_4,ghost_location_5,\n",
        "                          ghost_location_6,ghost_location_7)\n",
        "\n",
        "          cumulative_reward += reward    #total reward collected\n",
        "          step += 1\n",
        "\n",
        "\n",
        "          if environment.check_state() == 'Agent has reached the goal': # If game is in terminal state, game over and start next trial\n",
        "              rand = np.random.uniform(0,1000)\n",
        "              e_s.append(rand)\n",
        "              environment.__init__()\n",
        "              game_over = True\n",
        "          elif environment.check_state() == 'Caught by bomb':\n",
        "              rand = np.random.uniform(0,1000)\n",
        "              g_s.append(rand)\n",
        "              environment.__init__()\n",
        "              game_over = True\n",
        "\n",
        "        reward_per_episode.append(cumulative_reward) # Append reward for current trial to performance log, list of rewards for each iteration\n",
        "    #when the ghosts stay in their changed or original positions.\n",
        "    else:\n",
        "          cumulative_reward = 0 # Initialise values of each game\n",
        "          step = 0\n",
        "          game_over = False\n",
        "          new_states = []\n",
        "          while step < max_steps_per_episode and game_over != True: # Run until max steps or until game is finished\n",
        "\n",
        "            old_state = environment.current_location             #defining old state\n",
        "            action = agent.choose_action(environment.actions)     #depending on whether we place agent as random agent or q agent\n",
        "            reward = environment.make_step(action)             #reward plus updation of current_location\n",
        "            new_state = environment.current_location\n",
        "            new_states.append(new_state)\n",
        "            if learn == True: # Update Q-values if learning is specified\n",
        "                agent.learn(old_state, reward, new_state, action,ghost_location,ghost_location_2,ghost_location_3,ghost_location_4,ghost_location_5,\n",
        "                            ghost_location_6,ghost_location_7)\n",
        "\n",
        "            cumulative_reward += reward    #total reward collected\n",
        "            step += 1\n",
        "\n",
        "\n",
        "            if environment.check_state() == 'Agent has reached the goal': # If game is in terminal state, game over and start next trial\n",
        "              rand = np.random.uniform(0,1000)\n",
        "              e_s.append(rand)\n",
        "              environment.__init__()\n",
        "              game_over = True\n",
        "            elif environment.check_state() == 'Caught by bomb':\n",
        "              rand = np.random.uniform(0,1000)\n",
        "              g_s.append(rand)\n",
        "              environment.__init__()\n",
        "              game_over = True\n",
        "\n",
        "          reward_per_episode.append(cumulative_reward) # Append reward for current trial to performance log, list of rewards for each iteration\n",
        "\n",
        "    return e_s,g_s,reward_per_episode, new_states,ghost_location,ghost_location_2,ghost_location_3,ghost_location_4,ghost_location_5,ghost_location_6,ghost_location_7    # Return performance log"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Learning Process"
      ],
      "metadata": {
        "id": "pv52HGVuIRLZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "u89RrypuDuce",
        "outputId": "475cc292-5f76-4da3-8f24-1f629294a8b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Latest location of the ghost state : (13, 4)\n",
            "Latest location of the ghost state_2 : (13, 6)\n",
            "Latest location of the ghost state_3 : (7, 7)\n",
            "Latest location of the ghost state_4 : (1, 10)\n",
            "Latest location of the ghost state_5 : (23, 24)\n",
            "Latest location of the ghost state_6 : (21, 3)\n",
            "Latest location of the ghost state_7 : (1, 20)\n",
            "Agent caught by a bomb : 423\n",
            "Agent reached the end  81\n",
            "Agent reaching its goal vs Agent caught by bomb : 16.071428571428573 % of time after 1000 iterations.\n",
            "Latest location of the ghost state : (16, 4)\n",
            "Latest location of the ghost state_2 : (17, 6)\n",
            "Latest location of the ghost state_3 : (1, 7)\n",
            "Latest location of the ghost state_4 : (0, 10)\n",
            "Latest location of the ghost state_5 : (22, 24)\n",
            "Latest location of the ghost state_6 : (21, 1)\n",
            "Latest location of the ghost state_7 : (1, 23)\n",
            "Agent caught by a bomb : 1423\n",
            "Agent reached the end  2111\n",
            "Agent reaching its goal vs Agent caught by bomb : 59.734012450481046 % of time after 7000 iterations.\n",
            "Latest location of the ghost state : (11, 4)\n",
            "Latest location of the ghost state_2 : (10, 6)\n",
            "Latest location of the ghost state_3 : (8, 7)\n",
            "Latest location of the ghost state_4 : (8, 10)\n",
            "Latest location of the ghost state_5 : (22, 24)\n",
            "Latest location of the ghost state_6 : (21, 1)\n",
            "Latest location of the ghost state_7 : (1, 24)\n",
            "Agent caught by a bomb : 1555\n",
            "Agent reached the end  4984\n",
            "Agent reaching its goal vs Agent caught by bomb : 76.21960544425754 % of time after 13000 iterations.\n",
            "Latest location of the ghost state : (4, 4)\n",
            "Latest location of the ghost state_2 : (3, 6)\n",
            "Latest location of the ghost state_3 : (2, 7)\n",
            "Latest location of the ghost state_4 : (2, 10)\n",
            "Latest location of the ghost state_5 : (23, 24)\n",
            "Latest location of the ghost state_6 : (21, 8)\n",
            "Latest location of the ghost state_7 : (1, 17)\n",
            "Agent caught by a bomb : 2694\n",
            "Agent reached the end  6800\n",
            "Agent reaching its goal vs Agent caught by bomb : 71.62418369496524 % of time after 19000 iterations.\n",
            "Latest location of the ghost state : (10, 4)\n",
            "Latest location of the ghost state_2 : (10, 6)\n",
            "Latest location of the ghost state_3 : (0, 7)\n",
            "Latest location of the ghost state_4 : (0, 10)\n",
            "Latest location of the ghost state_5 : (23, 24)\n",
            "Latest location of the ghost state_6 : (21, 1)\n",
            "Latest location of the ghost state_7 : (1, 23)\n",
            "Agent caught by a bomb : 3075\n",
            "Agent reached the end  9450\n",
            "Agent reaching its goal vs Agent caught by bomb : 75.44910179640718 % of time after 25000 iterations.\n",
            "Latest location of the ghost state : (9, 4)\n",
            "Latest location of the ghost state_2 : (9, 6)\n",
            "Latest location of the ghost state_3 : (2, 7)\n",
            "Latest location of the ghost state_4 : (1, 10)\n",
            "Latest location of the ghost state_5 : (23, 24)\n",
            "Latest location of the ghost state_6 : (21, 0)\n",
            "Latest location of the ghost state_7 : (1, 18)\n",
            "Agent caught by a bomb : 2880\n",
            "Agent reached the end  12714\n",
            "Agent reaching its goal vs Agent caught by bomb : 81.53135821469796 % of time after 31000 iterations.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "environment = GridWorld()\n",
        "agentQ = Q_Agent(environment)\n",
        "TRAILS = []\n",
        "WIN_PERCENTAGE= []\n",
        "for t in range(1000,32000,6000):\n",
        "  TRAILS.append(t)\n",
        "  e_s,g_s,reward_per_episode,new_states, ghost_location,ghost_location_2,ghost_location_3,ghost_location_4,ghost_location_5,ghost_location_6,ghost_location_7  = play(environment, agentQ,trials=t, learn=True)\n",
        "  win = len(e_s)/(len(e_s)+len(g_s))\n",
        "  WIN_PERCENTAGE.append(win)\n",
        "  print(\"Latest location of the ghost state :\",ghost_location)\n",
        "  print(\"Latest location of the ghost state_2 :\",ghost_location_2)\n",
        "  print(\"Latest location of the ghost state_3 :\",ghost_location_3)\n",
        "  print(\"Latest location of the ghost state_4 :\",ghost_location_4)\n",
        "  print(\"Latest location of the ghost state_5 :\",ghost_location_5)\n",
        "  print(\"Latest location of the ghost state_6 :\",ghost_location_6)\n",
        "  print(\"Latest location of the ghost state_7 :\",ghost_location_7)\n",
        "  print(\"Agent caught by a bomb :\", len(g_s))\n",
        "  print(\"Agent reached the end \", len(e_s))\n",
        "  print(\"Agent reaching its goal vs Agent caught by bomb :\",(len(e_s)/(len(e_s)+len(g_s)))*100,\"% of time after\", t, \"iterations.\")\n",
        "# Simple learning curve\n",
        "\n",
        "  plt.plot(reward_per_episode)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(TRAILS,WIN_PERCENTAGE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "-sTL9Z7rfvjs",
        "outputId": "168ee00a-fcb5-494a-b6f7-79ae0fc309a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fa9c193a290>]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see from the above graph our agent is learning with each iteration & is reaching the end state more often than it did in earlier iterations."
      ],
      "metadata": {
        "id": "SkDITbVfybYF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "_gNKYtFKFMtp",
        "outputId": "b78fe2dc-e5f7-4656-f3a2-35b3386b7289"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 1), (0, 1), (0, 2), (0, 2), (1, 2), (0, 2), (0, 1), (0, 2), (0, 3), (0, 2), (1, 2), (1, 2), (0, 2), (0, 3), (0, 4), (1, 4), (1, 5), (0, 5), (0, 5), (0, 4), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (1, 8), (1, 9), (2, 9), (1, 9), (2, 9), (3, 9), (4, 9), (5, 9), (6, 9), (7, 9), (8, 9), (9, 9), (10, 9), (11, 9), (12, 9), (12, 10), (12, 11), (13, 11), (13, 10), (14, 10), (15, 10), (16, 10), (15, 10), (16, 10), (17, 10), (18, 10), (19, 10), (20, 10), (21, 10), (21, 11), (21, 12), (21, 13), (21, 14), (21, 13), (21, 14), (21, 15), (21, 16), (21, 16), (21, 16), (21, 17), (21, 18), (21, 19), (21, 19), (21, 20), (21, 21), (21, 22), (21, 22), (21, 22), (21, 22), (21, 22), (21, 23), (22, 23), (23, 23), (24, 23), (24, 22), (24, 21), (24, 20), (24, 19), (24, 18), (24, 19), (24, 20), (24, 20), (24, 19), (23, 19), (24, 19), (24, 18), (24, 17), (24, 16), (24, 15), (24, 14), (24, 13), (24, 14), (24, 14), (24, 13), (24, 12), (24, 11), (24, 10), (24, 9), (24, 8), (24, 7), (24, 6), (24, 5), (24, 4), (24, 3), (24, 2), (23, 2), (23, 1), (23, 2), (23, 1), (23, 1), (23, 0), (24, 0)]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "print(new_states)\n",
        "x_axis = []\n",
        "y_axis = []\n",
        "for i in new_states:\n",
        "  x_axis.append(i[0])\n",
        "  y_axis.append(i[1])\n",
        "plt.plot(x_axis, y_axis, color='green', linestyle='dashed', linewidth = 3,\n",
        "         marker='o', markerfacecolor='blue', markersize=12)\n",
        "plt.title('Path followed by the agent')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Map showing how the agent reached its final goal."
      ],
      "metadata": {
        "id": "n5LmsJ5ZIn-y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etiP2FB7EveE"
      },
      "outputs": [],
      "source": [
        "def showRoute(states,gl,gl_2,gl_3,gl_4,gl_5,gl_6,gl_7):\n",
        "    board = np.zeros([25, 25])\n",
        "    height = 25\n",
        "    width = 25\n",
        "    IS = (0, 0)\n",
        "    D = (24, 0)\n",
        "    G = gl\n",
        "    G_2 = gl_2\n",
        "    G_3 = gl_3\n",
        "    G_4 = gl_4\n",
        "    G_5 = gl_5\n",
        "    G_6 = gl_6\n",
        "    G_7 = gl_7\n",
        "    # add grid marked as -1\n",
        "    board[2:21, 5] = -math.inf\n",
        "    board[2:21,0] = -math.inf\n",
        "    board[2:21,2] = -math.inf\n",
        "    board[2:21,8] = -math.inf\n",
        "    board[5,11:24] = -math.inf\n",
        "    board[8,11:24] = -math.inf\n",
        "    board[11, 11:24] = -math.inf\n",
        "    board[14,11:24] = -math.inf\n",
        "    board[17,11:24] = -math.inf\n",
        "    board[20,11:24] = -math.inf\n",
        "    board[22,0:24] = -math.inf\n",
        "        # Set random start locatio\n",
        "    for i in range(0, height):\n",
        "        print('---------------------------------------------------------------------------------------------------------------------------------')\n",
        "        out = ' | '\n",
        "        for j in range(0, width):\n",
        "            token = '. '\n",
        "            if board[i, j] == -math.inf:\n",
        "                token = '‚ñÜ'\n",
        "            if (i, j) in states:\n",
        "                token = '‚ôõ'\n",
        "            if (i, j) == G:\n",
        "                token = ' ‚ò†Ô∏è'\n",
        "            if (i, j) == G_2:\n",
        "                token = ' ‚ò†Ô∏è'\n",
        "            if (i, j) == G_3:\n",
        "                token = '‚ò†Ô∏è'\n",
        "            if (i, j) == G_4:\n",
        "                token = '‚ò†Ô∏è'\n",
        "            if (i, j) == G_5:\n",
        "                token = ' ‚ò†Ô∏è'\n",
        "            if (i, j) == G_6:\n",
        "                token = '‚ò†Ô∏è'\n",
        "            if (i, j) == G_7:\n",
        "                token = '‚ò†Ô∏è'\n",
        "            if (i,j) == IS:\n",
        "                token = 'IS'\n",
        "            if (i,j) == D:\n",
        "                token = ' üçï üçï'\n",
        "            out += token + ' | '\n",
        "        print(out)\n",
        "    print('----------------------------------------------------------------------------------------------------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEarL9vVFBRd",
        "outputId": "c196f064-475c-4846-cc03-87d9d2f394d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------------------------------------------------------\n",
            " | IS | ‚ôõ | ‚ôõ | ‚ôõ | ‚ôõ | ‚ôõ | ‚ôõ | ‚ôõ | ‚ôõ | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | \n",
            "---------------------------------------------------------------------------------------------------------------------------------\n",
            " | .  | .  | ‚ôõ | .  | ‚ôõ | ‚ôõ | .  | .  | ‚ôõ | ‚ôõ | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | ‚ò†Ô∏è | \n",
            "---------------------------------------------------------------------------------------------------------------------------------\n",
            " | ‚ñÜ | .  | ‚ñÜ | .  | .  | ‚ñÜ | .  | .  | ‚ñÜ | ‚ôõ | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | \n",
            "---------------------------------------------------------------------------------------------------------------------------------\n",
            " | ‚ñÜ | .  | ‚ñÜ | .  |  ‚ò†Ô∏è | ‚ñÜ |  ‚ò†Ô∏è | .  | ‚ñÜ | ‚ôõ | ‚ò†Ô∏è | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | \n",
            "---------------------------------------------------------------------------------------------------------------------------------\n",
            " | ‚ñÜ | .  | ‚ñÜ | .  | .  | ‚ñÜ | .  | ‚ò†Ô∏è | ‚ñÜ | ‚ôõ | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | \n",
            "---------------------------------------------------------------------------------------------------------------------------------\n",
            " | ‚ñÜ | .  | ‚ñÜ | .  | .  | ‚ñÜ | .  | .  | ‚ñÜ | ‚ôõ | .  | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | .  | \n",
            "---------------------------------------------------------------------------------------------------------------------------------\n",
            " | ‚ñÜ | .  | ‚ñÜ | .  | .  | ‚ñÜ | .  | .  | ‚ñÜ | ‚ôõ | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | \n",
            "---------------------------------------------------------------------------------------------------------------------------------\n",
            " | ‚ñÜ | .  | ‚ñÜ | .  | .  | ‚ñÜ | .  | .  | ‚ñÜ | ‚ôõ | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | \n",
            "---------------------------------------------------------------------------------------------------------------------------------\n",
            " | ‚ñÜ | .  | ‚ñÜ | .  | .  | ‚ñÜ | .  | .  | ‚ñÜ | ‚ôõ | .  | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | .  | \n",
            "---------------------------------------------------------------------------------------------------------------------------------\n",
            " | ‚ñÜ | .  | ‚ñÜ | .  | .  | ‚ñÜ | .  | .  | ‚ñÜ | ‚ôõ | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | \n",
            "---------------------------------------------------------------------------------------------------------------------------------\n",
            " | ‚ñÜ | .  | ‚ñÜ | .  | .  | ‚ñÜ | .  | .  | ‚ñÜ | ‚ôõ | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | \n",
            "---------------------------------------------------------------------------------------------------------------------------------\n",
            " | ‚ñÜ | .  | ‚ñÜ | .  | .  | ‚ñÜ | .  | .  | ‚ñÜ | ‚ôõ | .  | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | .  | \n",
            "---------------------------------------------------------------------------------------------------------------------------------\n",
            " | ‚ñÜ | .  | ‚ñÜ | .  | .  | ‚ñÜ | .  | .  | ‚ñÜ | ‚ôõ | ‚ôõ | ‚ôõ | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | \n",
            "---------------------------------------------------------------------------------------------------------------------------------\n",
            " | ‚ñÜ | .  | ‚ñÜ | .  | .  | ‚ñÜ | .  | .  | ‚ñÜ | .  | ‚ôõ | ‚ôõ | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | \n",
            "---------------------------------------------------------------------------------------------------------------------------------\n",
            " | ‚ñÜ | .  | ‚ñÜ | .  | .  | ‚ñÜ | .  | .  | ‚ñÜ | .  | ‚ôõ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | .  | \n",
            "---------------------------------------------------------------------------------------------------------------------------------\n",
            " | ‚ñÜ | .  | ‚ñÜ | .  | .  | ‚ñÜ | .  | .  | ‚ñÜ | .  | ‚ôõ | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | \n",
            "---------------------------------------------------------------------------------------------------------------------------------\n",
            " | ‚ñÜ | .  | ‚ñÜ | .  | .  | ‚ñÜ | .  | .  | ‚ñÜ | .  | ‚ôõ | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | \n",
            "---------------------------------------------------------------------------------------------------------------------------------\n",
            " | ‚ñÜ | .  | ‚ñÜ | .  | .  | ‚ñÜ | .  | .  | ‚ñÜ | .  | ‚ôõ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | .  | \n",
            "---------------------------------------------------------------------------------------------------------------------------------\n",
            " | ‚ñÜ | .  | ‚ñÜ | .  | .  | ‚ñÜ | .  | .  | ‚ñÜ | .  | ‚ôõ | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | \n",
            "---------------------------------------------------------------------------------------------------------------------------------\n",
            " | ‚ñÜ | .  | ‚ñÜ | .  | .  | ‚ñÜ | .  | .  | ‚ñÜ | .  | ‚ôõ | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  |  ‚ò†Ô∏è | \n",
            "---------------------------------------------------------------------------------------------------------------------------------\n",
            " | ‚ñÜ | .  | ‚ñÜ | .  | .  | ‚ñÜ | .  | .  | ‚ñÜ | .  | ‚ôõ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | .  | \n",
            "---------------------------------------------------------------------------------------------------------------------------------\n",
            " | .  | ‚ò†Ô∏è | .  | .  | .  | .  | .  | .  | .  | .  | ‚ôõ | ‚ôõ | ‚ôõ | ‚ôõ | ‚ôõ | ‚ôõ | ‚ôõ | ‚ôõ | ‚ôõ | ‚ôõ | ‚ôõ | ‚ôõ | ‚ôõ | ‚ôõ | .  | \n",
            "---------------------------------------------------------------------------------------------------------------------------------\n",
            " | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ñÜ | ‚ôõ | .  | \n",
            "---------------------------------------------------------------------------------------------------------------------------------\n",
            " | ‚ôõ | ‚ôõ | ‚ôõ | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | .  | ‚ôõ | .  | .  | .  | ‚ôõ | .  | \n",
            "---------------------------------------------------------------------------------------------------------------------------------\n",
            " |  üçï üçï | .  | ‚ôõ | ‚ôõ | ‚ôõ | ‚ôõ | ‚ôõ | ‚ôõ | ‚ôõ | ‚ôõ | ‚ôõ | ‚ôõ | ‚ôõ | ‚ôõ | ‚ôõ | ‚ôõ | ‚ôõ | ‚ôõ | ‚ôõ | ‚ôõ | ‚ôõ | ‚ôõ | ‚ôõ | ‚ôõ | .  | \n",
            "----------------------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "showRoute(new_states,ghost_location,ghost_location_2,ghost_location_3,ghost_location_4,ghost_location_5,ghost_location_6,ghost_location_7)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**As we can see the the agent successfully reached its final destination.**"
      ],
      "metadata": {
        "id": "kfsEqxEwI8JT"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}